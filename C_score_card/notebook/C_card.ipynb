{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T13:20:58.934056Z",
     "start_time": "2020-08-23T13:20:58.930047Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import strptime,mktime\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T13:19:28.548497Z",
     "start_time": "2020-08-23T13:19:28.540475Z"
    }
   },
   "outputs": [],
   "source": [
    "def LogitRR(x):\n",
    "    '''\n",
    "    :param x: 划款率，有的超过1，有的为0.做截断处理\n",
    "    :return: 将还款率转化成logit变换\n",
    "    '''\n",
    "    if x >= 1:\n",
    "        y = 0.9999\n",
    "    elif x == 0:\n",
    "        y = 0.0001\n",
    "    else:\n",
    "        y = x\n",
    "    return np.log(y/(1-y))\n",
    "\n",
    "def MakeupMissingCategorical(x):\n",
    "    if str(x) == 'nan':\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def MakeupMissingNumerical(x,replacement):\n",
    "    if np.isnan(x):\n",
    "        return replacement\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T13:19:28.779252Z",
     "start_time": "2020-08-23T13:19:28.550501Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "第一步：文件准备\n",
    "'''\n",
    "# foldOfData = 'C:/Users/OkO/Desktop/Financial Data Analsys/3nd Series/Data/'\n",
    "mydata = pd.read_csv(\"prosperLoanData_chargedoff.csv\",header = 0)\n",
    "#催收还款率等于催收金额/（所欠本息+催收费用）。其中催收费用以支出形式表示\n",
    "mydata['rec_rate'] = mydata.apply(lambda x: x.LP_NonPrincipalRecoverypayments /(x.AmountDelinquent-x.LP_CollectionFees), axis=1)\n",
    "mydata['rec_rate'] = mydata['rec_rate'].map(lambda x: min(x,1))\n",
    "#mydata['recovery_status'] = mydata['rec_rate'].map(lambda x: x<=0.5)\n",
    "#还款率是0~1之间的数，需要通过logit变换，映射到实数空间\n",
    "#mydata['logit_rr'] = mydata['rec_rate'].map(LogitRR)\n",
    "#整个开发数据分为训练集、测试集2个部分\n",
    "trainData, testData = train_test_split(mydata,test_size=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T13:21:03.595431Z",
     "start_time": "2020-08-23T13:21:03.543293Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "第二步：数据预处理\n",
    "'''\n",
    "categoricalFeatures = ['CreditGrade','Term','BorrowerState','Occupation','EmploymentStatus','IsBorrowerHomeowner','CurrentlyInGroup','IncomeVerifiable']\n",
    "\n",
    "numFeatures = ['BorrowerAPR','BorrowerRate','LenderYield','ProsperRating (numeric)','ProsperScore','ListingCategory (numeric)','EmploymentStatusDuration','CurrentCreditLines',\n",
    "                'OpenCreditLines','TotalCreditLinespast7years','CreditScoreRangeLower','OpenRevolvingAccounts','OpenRevolvingMonthlyPayment','InquiriesLast6Months','TotalInquiries',\n",
    "               'CurrentDelinquencies','DelinquenciesLast7Years','PublicRecordsLast10Years','PublicRecordsLast12Months','BankcardUtilization','TradesNeverDelinquent (percentage)',\n",
    "               'TradesOpenedLast6Months','DebtToIncomeRatio','LoanFirstDefaultedCycleNumber','LoanMonthsSinceOrigination','PercentFunded','Recommendations','InvestmentFromFriendsCount',\n",
    "               'Investors']\n",
    "\n",
    "'''\n",
    "类别型变量需要用目标变量的均值进行编码\n",
    "'''\n",
    "encodedFeatures = []\n",
    "encodedDict = {}\n",
    "for var in categoricalFeatures:\n",
    "    trainData[var] = trainData[var].map(MakeupMissingCategorical)\n",
    "    avgTarget = trainData.groupby([var])['rec_rate'].mean()\n",
    "    avgTarget = avgTarget.to_dict()\n",
    "    newVar = var + '_encoded'\n",
    "    trainData[newVar] = trainData[var].map(avgTarget)\n",
    "    encodedFeatures.append(newVar)\n",
    "    encodedDict[var] = avgTarget\n",
    "\n",
    "#对数值型数据的缺失进行补缺\n",
    "trainData['ProsperRating (numeric)'] = trainData['ProsperRating (numeric)'].map(lambda x: MakeupMissingNumerical(x,0))\n",
    "trainData['ProsperScore'] = trainData['ProsperScore'].map(lambda x: MakeupMissingNumerical(x,0))\n",
    "\n",
    "avgDebtToIncomeRatio = np.mean(trainData['DebtToIncomeRatio'])\n",
    "trainData['DebtToIncomeRatio'] = trainData['DebtToIncomeRatio'].map(lambda x: MakeupMissingNumerical(x,avgDebtToIncomeRatio))\n",
    "numFeatures2 = numFeatures + encodedFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T14:06:12.303161Z",
     "start_time": "2020-08-23T13:59:08.430180Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-aeb5a2aaf1ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumFeatures2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'less_rr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "'''\n",
    "第三步：调参\n",
    "对基于CART的随机森林的调参，主要有：\n",
    "1，树的个数\n",
    "2，树的最大深度\n",
    "3，内部节点最少样本数与叶节点最少样本数\n",
    "4，特征个数\n",
    "\n",
    "此外，调参过程中选择的误差函数是均值误差，5倍折叠\n",
    "'''\n",
    "X, y= trainData[numFeatures2],trainData['rec_rate']\n",
    "\n",
    "param_test1 = {'n_estimators':range(10,80,5)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestRegressor(min_samples_split=50,min_samples_leaf=10,max_depth=8,max_features='sqrt' ,random_state=10),\n",
    "                       param_grid = param_test1, scoring='neg_mean_squared_error',cv=5)\n",
    "gsearch1.fit(X,y)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n",
    "best_n_estimators = gsearch1.best_params_['n_estimators']\n",
    "\n",
    "param_test2 = {'max_depth':range(3,21), 'min_samples_split':range(10,100,10)}\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestRegressor(n_estimators=best_n_estimators, min_samples_leaf=10,max_features='sqrt' ,random_state=10,oob_score=True),\n",
    "                       param_grid = param_test2, scoring='neg_mean_squared_error',cv=5)\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.best_params_, gsearch2.best_score_\n",
    "best_max_depth = gsearch2.best_params_['max_depth']\n",
    "best_min_sample_split = gsearch2.best_params_['min_samples_split']\n",
    "\n",
    "param_test3 = {'min_samples_split':range(50,201,10), 'min_samples_leaf':range(1,20,2)}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestRegressor(n_estimators=best_n_estimators, max_depth = best_max_depth,max_features='sqrt',random_state=10,oob_score=True),\n",
    "                       param_grid = param_test3, scoring='neg_mean_squared_error',cv=5)\n",
    "gsearch3.fit(X,y)\n",
    "gsearch3.best_params_, gsearch3.best_score_\n",
    "best_min_samples_leaf = gsearch3.best_params_['min_samples_leaf']\n",
    "best_min_samples_split = gsearch3.best_params_['min_samples_split']\n",
    "\n",
    "numOfFeatures = len(numFeatures2)\n",
    "mostSelectedFeatures = numOfFeatures/2\n",
    "param_test4 = {'max_features':range(3,numOfFeatures+1)}\n",
    "gsearch4 = GridSearchCV(estimator = RandomForestRegressor(n_estimators=best_n_estimators, max_depth=best_max_depth,min_samples_leaf=best_min_samples_leaf,\n",
    "                                                          min_samples_split=best_min_samples_split,random_state=10,oob_score=True),\n",
    "                       param_grid = param_test4, scoring='neg_mean_squared_error',cv=5)\n",
    "gsearch4.fit(X,y)\n",
    "gsearch4.best_params_, gsearch4.best_score_\n",
    "best_max_features = gsearch4.best_params_['max_features']\n",
    "\n",
    "cls = RandomForestRegressor(n_estimators=best_n_estimators,\n",
    "                            max_depth=best_max_depth,\n",
    "                            min_samples_leaf=best_min_samples_leaf,\n",
    "                            min_samples_split=best_min_samples_split,\n",
    "                            max_features=best_max_features,\n",
    "                            random_state=10,\n",
    "                            oob_score=True)\n",
    "\n",
    "cls.fit(X,y)\n",
    "\n",
    "trainData['pred'] = cls.predict(trainData[numFeatures2])\n",
    "trainData['less_rr'] = trainData.apply(lambda x: int(x.pred > x.rec_rate), axis=1)\n",
    "np.mean(trainData['less_rr'])\n",
    "err = trainData.apply(lambda x: np.abs(x.pred - x.rec_rate), axis=1)\n",
    "np.mean(err)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T13:35:16.591780Z",
     "start_time": "2020-08-23T13:35:16.354147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11291960111967676"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "第四步：在测试集上测试效果\n",
    "'''\n",
    "\n",
    "for var in categoricalFeatures:\n",
    "    testData[var] = testData[var].map(MakeupMissingCategorical)\n",
    "    newVar = var + '_encoded'\n",
    "    testData[newVar] = testData[var].map(encodedDict[var])\n",
    "    avgnewVar = np.mean(trainData[newVar])\n",
    "    testData[newVar] = testData[newVar].map(lambda x: MakeupMissingNumerical(x, avgnewVar))\n",
    "\n",
    "testData['ProsperRating (numeric)'] = testData['ProsperRating (numeric)'].map(lambda x: MakeupMissingNumerical(x,0))\n",
    "testData['ProsperScore'] = testData['ProsperScore'].map(lambda x: MakeupMissingNumerical(x,0))\n",
    "testData['DebtToIncomeRatio'] = testData['DebtToIncomeRatio'].map(lambda x: MakeupMissingNumerical(x,avgDebtToIncomeRatio))\n",
    "\n",
    "testData['pred'] = cls.predict(testData[numFeatures2])\n",
    "testData['less_rr'] = testData.apply(lambda x: int(x.pred > x.rec_rate), axis=1)\n",
    "np.mean(testData['less_rr'])\n",
    "err = testData.apply(lambda x: np.abs(x.pred - x.rec_rate), axis=1)\n",
    "np.mean(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
